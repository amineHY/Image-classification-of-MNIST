{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-lab-11-2-mnist_deep_cnn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amineHY/Image-classification-of-MNIST/blob/master/pytorch_mnist_deep_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Iq3huxweBp9B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image classification from  MNIST dataset using Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "U5-bxSFa4ApQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a31d7c3c-a2c3-41cc-8580-a40c0c3af219"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init\n",
        "\n",
        "torch.manual_seed(777)  # reproducibility"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fba8bd66f50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "metadata": {
        "id": "d0697fDu4B9v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# hyper-parameters\n",
        "batch_size = 32\n",
        "keep_prob = 1 # 0.7"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0xDxbPD4KIG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwiQmlTzc8dq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "bb05fb8f-9249-40e2-d7f7-d1fc14542665"
      },
      "cell_type": "code",
      "source": [
        "# Display informations about the dataset\n",
        "print('The training dataset:\\t',mnist_train)\n",
        "print('\\nThe testing dataset:\\t',mnist_test)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training dataset:\t Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Split: train\n",
            "    Root Location: MNIST_data/\n",
            "    Transforms (if any): ToTensor()\n",
            "    Target Transforms (if any): None\n",
            "The testing dataset:\t Dataset MNIST\n",
            "    Number of datapoints: 10000\n",
            "    Split: test\n",
            "    Root Location: MNIST_data/\n",
            "    Transforms (if any): ToTensor()\n",
            "    Target Transforms (if any): None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vBHSMiyb7TdS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The CNN architecture we used in this notebook is proposed [ here ](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/index.html)\n",
        "\n",
        "![Architecture of the CNN…](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)"
      ]
    },
    {
      "metadata": {
        "id": "cI-bmhxJ4MYA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc6f798d-cbe3-4af3-d0c5-3337c44828c8"
      },
      "cell_type": "code",
      "source": [
        "# Implementation of CNN/ConvNet Model using PyTorch (depicted in the picture above)\n",
        "\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # L1 ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Dropout(p=1 - keep_prob))\n",
        "        # L2 ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64)\n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            torch.nn.Dropout(p=1 - keep_prob))\n",
        "        # L3 ImgIn shape=(?, 7, 7, 64)\n",
        "        #    Conv      ->(?, 7, 7, 128)\n",
        "        #    Pool      ->(?, 4, 4, 128)\n",
        "        self.layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=1),\n",
        "            torch.nn.Dropout(p=1 - keep_prob))\n",
        "\n",
        "        # L4 FC 4x4x128 inputs -> 625 outputs\n",
        "        self.fc1 = torch.nn.Linear(4 * 4 * 128, 625, bias=True)\n",
        "        torch.nn.init.xavier_uniform(self.fc1.weight)\n",
        "        self.layer4 = torch.nn.Sequential(\n",
        "            self.fc1,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Dropout(p=1 - keep_prob))\n",
        "        # L5 Final FC 625 inputs -> 10 outputs\n",
        "        self.fc2 = torch.nn.Linear(625, 10, bias=True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc2.weight) # initialize parameters\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = out.view(out.size(0), -1)   # Flatten them for FC\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# instantiate CNN model\n",
        "model = CNN()\n",
        "model"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:33: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "A54tSlL-I5Lf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Affichage des parametres du réseaux pour chaque couche\n",
        "\n",
        "*   Weight\n",
        "*   Biais\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "M-y4Qv1aI1zl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "bea599d1-e640-428e-f4e3-110e46655257"
      },
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    print(param.size())"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([32, 1, 3, 3])\n",
            "torch.Size([32])\n",
            "torch.Size([64, 32, 3, 3])\n",
            "torch.Size([64])\n",
            "torch.Size([128, 64, 3, 3])\n",
            "torch.Size([128])\n",
            "torch.Size([625, 2048])\n",
            "torch.Size([625])\n",
            "torch.Size([10, 625])\n",
            "torch.Size([10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "D8EKHIn3JWtH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Definition de la fonction cout et l'algorithme d'optimisation"
      ]
    },
    {
      "metadata": {
        "id": "k_zg08ibH6u1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "criterion = torch.nn.CrossEntropyLoss()    # Softmax is internally computed.\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-A7hBuQ1EYRA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The cross-entropy cost function is defined as follow : \n",
        "$\\text{loss}(x, class) = -\\log\\left(\\frac{\\exp(x[class])}{\\sum_j \\exp(x[j])}\\right)\n",
        "= -x[class] + \\log\\left(\\sum_j \\exp(x[j])\\right)$"
      ]
    },
    {
      "metadata": {
        "id": "UlReN4_SJOIK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Apprentissage du modèle"
      ]
    },
    {
      "metadata": {
        "id": "47opBzQk4QNA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "9fedef5d-961d-46b3-c0be-845f14ecb117"
      },
      "cell_type": "code",
      "source": [
        "print('Training the Deep Learning network ...')\n",
        "train_cost = []\n",
        "train_accu = []\n",
        "\n",
        "training_epochs = 15\n",
        "total_batch = len(mnist_train) // batch_size\n",
        "\n",
        "print('Size of the training dataset is {}'.format(mnist_train.data.size()))\n",
        "print('Size of the testing dataset'.format(mnist_test.data.size()))\n",
        "print('Batch size is : {}'.format(batch_size))\n",
        "print('Total number of batches is : {0:2.0f}'.format(total_batch))\n",
        "print('\\nTotal number of epochs is : {0:2.0f}'.format(training_epochs))\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    for i, (batch_X, batch_Y) in enumerate(data_loader):\n",
        "        X = Variable(batch_X)    # image is already size of (28x28), no reshape\n",
        "        Y = Variable(batch_Y)    # label is not one-hot encoded\n",
        "\n",
        "        optimizer.zero_grad() # <= initialization of the gradients\n",
        "        \n",
        "        # forward propagation\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y) # <= compute the loss function\n",
        "        \n",
        "        # Backward propagation\n",
        "        cost.backward() # <= compute the gradient of the loss/cost function     \n",
        "        optimizer.step() # <= Update the gradients\n",
        "             \n",
        "        # Print some performance to monitor the training\n",
        "        prediction = hypothesis.data.max(dim=1)[1]\n",
        "        train_accu.append(((prediction.data == Y.data).float().mean()).item())\n",
        "        train_cost.append(cost.item())   \n",
        "        if i % 200 == 0:\n",
        "            print(\"Epoch= {},\\t batch = {},\\t cost = {:2.4f},\\t accuracy = {}\".format(epoch+1, i, train_cost[-1], train_accu[-1]))\n",
        "       \n",
        "        avg_cost += cost.data / total_batch\n",
        "\n",
        "    print(\"[Epoch: {:>4}], averaged cost = {:>.9}\".format(epoch + 1, avg_cost.item()))\n",
        "\n",
        "\n",
        "print('Learning Finished!')\n",
        "#  _, argmax = torch.max(outputs, 1)\n",
        "accuracy = (labels == argmax.squeeze()).float().mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the Deep Learning network ...\n",
            "\n",
            "Total number of epochs is : 15\n",
            "Total number of batches is : 1875\n",
            "[Epoch:    1] cost = 0.124820858\n",
            "[Epoch:    2] cost = 0.0454975255\n",
            "[Epoch:    3] cost = 0.0342978314\n",
            "[Epoch:    4] cost = 0.0271685198\n",
            "[Epoch:    5] cost = 0.0235471297\n",
            "[Epoch:    6] cost = 0.0201890636\n",
            "[Epoch:    7] cost = 0.0180015843\n",
            "[Epoch:    8] cost = 0.0159422997\n",
            "[Epoch:    9] cost = 0.0138327638\n",
            "[Epoch:   10] cost = 0.0150435949\n",
            "[Epoch:   11] cost = 0.0112169087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZdLt7D8KJrht",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Afficher la courbe du critère lors de l'apprentissage"
      ]
    },
    {
      "metadata": {
        "id": "yZ0EXcLmJrK7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pylab as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(121), plt.plot(np.arange(len(train_cost)), train_cost), plt.ylim([0,10])\n",
        "plt.subplot(122), plt.plot(np.arange(len(train_accu)), 100 * torch.as_tensor(train_accu).numpy()), plt.ylim([0,100])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lYYu2Wxk8lfA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost.item?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ze4e9fjbBibY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Test model and check accuracy\n",
        "model.eval()    # set the model to evaluation mode (dropout=False)\n",
        "\n",
        "X_test = Variable(mnist_test.data.view(len(mnist_test), 1, 28, 28).float())\n",
        "Y_test = Variable(mnist_test.targets)\n",
        "\n",
        "prediction = model(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "correct_prediction = (torch.max(prediction.data, dim=1)[1] == Y_test.data)\n",
        "accuracy = correct_prediction.float().mean().item()\n",
        "print('\\nAccuracy: {:2.2f} %'.format(accuracy*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5NlJpKfy3-Ly",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pylab as plt\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,15), facecolor='white')\n",
        "for i in torch.arange(0,12):\n",
        "  val, idx = torch.max(prediction, dim=1)\n",
        "  plt.subplot(4,4,i+1)  \n",
        "  plt.imshow(X_test[i][0])\n",
        "  plt.title('This image contains: {0:>2} '.format(idx[i].item()))\n",
        "  plt.xticks([]), plt.yticks([])\n",
        "  plt.plt.subplots_adjust()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}